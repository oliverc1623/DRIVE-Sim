{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mijanr/TimeSeries/blob/master/Time-Series%20Classification/cnn_plus_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JRB8m0tRWTo1"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tslearn.datasets import UCR_UEA_datasets\n",
        "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler, TimeSeriesScalerMinMax\n",
        "\n",
        "from typing import List\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5jfPWQgBWTo5"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'ElectricDevices'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YvnzpXcuWTo7"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the time series data\n",
        "X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset(dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odjHcgDaWTo8",
        "outputId": "962b2c5e-7612-4725-bdb6-c616766dd0a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([8926, 96, 1]),\n",
              " torch.Size([8926]),\n",
              " torch.Size([7711, 96, 1]),\n",
              " torch.Size([7711]))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qa2kJLU2WTo_"
      },
      "outputs": [],
      "source": [
        "#normalize the data\n",
        "X_train = TimeSeriesScalerMinMax().fit_transform(X_train)\n",
        "X_test = TimeSeriesScalerMinMax().fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d6LUFbKfWTpA"
      },
      "outputs": [],
      "source": [
        "# Resample the data to 128 time steps\n",
        "# X_train = TimeSeriesResampler(sz=128).fit_transform(X_train)\n",
        "# X_test = TimeSeriesResampler(sz=128).fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A-SGAmD5WTpB"
      },
      "outputs": [],
      "source": [
        "# Convert the data to torch tensors\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "y_test = torch.from_numpy(y_test).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qMzzIQrHWTpC"
      },
      "outputs": [],
      "source": [
        "#start class from 0\n",
        "y_train = y_train - 1\n",
        "y_test = y_test - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W0UG2krzWTpD"
      },
      "outputs": [],
      "source": [
        "#Datasets\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "#Dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([30, 96, 1])\n"
          ]
        }
      ],
      "source": [
        "for i, (x,y) in enumerate(train_loader):\n",
        "    print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model 1: CNN + LSTM\n",
        "# model 2: LSTM + CNN\n",
        "# model 3: CNN LSTM parallel\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #cnn takes input of shape (batch_size, channels, seq_len)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        out = self.cnn(x)\n",
        "        # lstm takes input of shape (batch_size, seq_len, input_size)\n",
        "        out = out.permute(0, 2, 1)\n",
        "        out, _ = self.lstm(out)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTM_CNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM_CNN, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=hidden_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            #flatten\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=256, out_features=num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out.permute(0, 2, 1)\n",
        "        out = self.cnn(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model 3: CNN LSTM parallel\n",
        "class ParallelCNNLSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(ParallelCNNLSTMModel, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=input_size, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(out_features=128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc_lstm = nn.Linear(hidden_size, 128)\n",
        "        self.fc = nn.Linear(128*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #cnn takes input of shape (batch_size, channels, seq_len)\n",
        "        x_cnn = x.permute(0, 2, 1)\n",
        "        out_cnn = self.cnn(x_cnn)\n",
        "        # lstm takes input of shape (batch_size, seq_len, input_size)\n",
        "        out_lstm, _ = self.lstm(x)\n",
        "        out_lstm = self.fc_lstm(out_lstm[:, -1, :])\n",
        "        out = torch.cat([out_cnn, out_lstm], dim=1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/oliverchang/opt/anaconda3/envs/vista/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ],
      "source": [
        "input_size = X_train.shape[-1]\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "cnn_lstm = CNN_LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "lstm_cnn = LSTM_CNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "cnn_lstm_parallel = ParallelCNNLSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7q2zEwkiWTpP"
      },
      "outputs": [],
      "source": [
        "def train(models:List, train_loader:DataLoader, epochs:int):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    for model in models:\n",
        "        print(\"Training model: \", model.__class__.__name__)\n",
        "        model.train()\n",
        "        optimizer = Adam(model.parameters(), lr=0.001)\n",
        "        for epoch in range(epochs):\n",
        "            for i, (x, y) in enumerate(train_loader):\n",
        "                x = x.to(device)\n",
        "                print(x.shape)\n",
        "                y = y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                y_pred = model(x)\n",
        "                loss = criterion(y_pred, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                if (i+1) % 10 == 0:\n",
        "                    print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "        print(\"Training completed for model: \", model.__class__.__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h3DZNLuWTpP",
        "outputId": "603adf68-4c05-4f90-c37c-32300fdc4878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model:  CNN_LSTM\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "Epoch [1/200], Step [10/140], Loss: 0.9359\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "Epoch [1/200], Step [20/140], Loss: 0.8671\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n",
            "torch.Size([64, 96, 1])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m models \u001b[39m=\u001b[39m [cnn_lstm, lstm_cnn, cnn_lstm_parallel]\n\u001b[1;32m      3\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m\n\u001b[0;32m----> 4\u001b[0m train(models, train_loader, epochs\u001b[39m=\u001b[39;49mnum_epochs)\n",
            "Cell \u001b[0;32mIn[17], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(models, train_loader, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     14\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_pred, y)\n\u001b[0;32m---> 15\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/vista/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/vista/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#train\n",
        "models = [cnn_lstm, lstm_cnn, cnn_lstm_parallel]\n",
        "num_epochs = 200\n",
        "train(models, train_loader, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "e60h3UIGWTpP"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "def test(models, test_loader):\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        accuracy_dict = {}\n",
        "        for model in models:\n",
        "            model.eval()\n",
        "            for x, y in test_loader:\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "                y_pred = model(x)\n",
        "                _, predicted = torch.max(y_pred.data, 1)\n",
        "                total += y.size(0)\n",
        "                correct += (predicted == y).sum().item()\n",
        "            print(f'Accuracy of the {model.__class__.__name__} model on the test set: {100 * correct / total:.2f} %')\n",
        "            accuracy_dict[model.__class__.__name__] = 100 * correct / total\n",
        "    return accuracy_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNouFrDJWTpQ",
        "outputId": "1fd38a45-3084-4225-d299-a7e8e4d156de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the CNN_LSTM model on the test set: 72.27 %\n",
            "Accuracy of the LSTM_CNN model on the test set: 69.73 %\n",
            "Accuracy of the ParallelCNNLSTMModel model on the test set: 69.84 %\n"
          ]
        }
      ],
      "source": [
        "accuracy_dict = test(models, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: >"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plot bar chart with the accuracy of each model\n",
        "sns.barplot(x=list(accuracy_dict.keys()), y=list(accuracy_dict.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.15 ('pytorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "77f0ac4a1ff910c6f832be6ab53afe92115f75471ff7ffff1273b50351d0e386"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
