{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b21828c-fb99-4d4b-934c-a5f2216cfdce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.distributions import Normal\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../vista_nautilus/models/')\n",
    "from transformer import Transformer\n",
    "\n",
    "class ActorCriticModel(nn.Module):\n",
    "    def __init__(self, config, observation_space, action_space_shape, max_episode_length):\n",
    "        \"\"\"Model setup\n",
    "\n",
    "        Arguments:\n",
    "            config {dict} -- Configuration and hyperparameters of the environment, trainer and model.\n",
    "            observation_space {box} -- Properties of the agent's observation space\n",
    "            action_space_shape {tuple} -- Dimensions of the action space\n",
    "            max_episode_length {int} -- The maximum number of steps in an episode\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden_size = config[\"hidden_layer_size\"]\n",
    "        self.memory_layer_size = config[\"transformer\"][\"embed_dim\"]\n",
    "        self.observation_space_shape = observation_space.shape\n",
    "        self.max_episode_length = max_episode_length\n",
    "\n",
    "        # Observation encoder\n",
    "        if len(self.observation_space_shape) > 1:\n",
    "            # Case: visual observation is available\n",
    "            # Visual encoder made of 3 convolutional layers\n",
    "            self.conv1 = nn.Conv2d(observation_space.shape[0], 32, 8, 4,)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 4, 2, 0)\n",
    "            self.conv3 = nn.Conv2d(64, 64, 3, 1, 0)\n",
    "            nn.init.orthogonal_(self.conv1.weight, np.sqrt(2))\n",
    "            nn.init.orthogonal_(self.conv2.weight, np.sqrt(2))\n",
    "            nn.init.orthogonal_(self.conv3.weight, np.sqrt(2))\n",
    "            # Compute output size of convolutional layers\n",
    "            self.conv_out_size = self.get_conv_output(observation_space.shape)\n",
    "            in_features_next_layer = self.conv_out_size\n",
    "        else:\n",
    "            # Case: vector observation is available\n",
    "            in_features_next_layer = observation_space.shape[0]\n",
    "        \n",
    "        # Hidden layer\n",
    "        self.lin_hidden = nn.Linear(in_features_next_layer, self.memory_layer_size)\n",
    "        nn.init.orthogonal_(self.lin_hidden.weight, np.sqrt(2))\n",
    "\n",
    "        # Transformer Blocks\n",
    "        self.transformer = Transformer(config[\"transformer\"], self.memory_layer_size, self.max_episode_length)\n",
    "\n",
    "        # Decouple policy from value\n",
    "        # Hidden layer of the policy\n",
    "        self.lin_policy = nn.Linear(self.memory_layer_size, self.hidden_size)\n",
    "        nn.init.orthogonal_(self.lin_policy.weight, np.sqrt(2))\n",
    "\n",
    "        # Hidden layer of the value function\n",
    "        self.lin_value = nn.Linear(self.memory_layer_size, self.hidden_size)\n",
    "        nn.init.orthogonal_(self.lin_value.weight, np.sqrt(2))\n",
    "\n",
    "        # Outputs / Model heads\n",
    "        # Policy (Multi-discrete categorical distribution)\n",
    "        self.policy_branches = nn.ModuleList()\n",
    "        for num_actions in action_space_shape:\n",
    "            actor_branch = nn.Linear(in_features=self.hidden_size, out_features=num_actions)\n",
    "            nn.init.orthogonal_(actor_branch.weight, np.sqrt(0.01))\n",
    "            self.policy_branches.append(actor_branch)\n",
    "            \n",
    "        # Value function\n",
    "        self.value = nn.Linear(self.hidden_size, 1)\n",
    "        nn.init.orthogonal_(self.value.weight, 1)\n",
    "\n",
    "    def forward(self, obs:torch.tensor, memory:torch.tensor, memory_mask:torch.tensor, memory_indices:torch.tensor):\n",
    "        \"\"\"Forward pass of the model\n",
    "\n",
    "        Arguments:\n",
    "            obs {torch.tensor} -- Batch of observations\n",
    "            memory {torch.tensor} -- Episodic memory window\n",
    "            memory_mask {torch.tensor} -- Mask to prevent the model from attending to the padding\n",
    "            memory_indices {torch.tensor} -- Indices to select the positional encoding that matches the memory window\n",
    "\n",
    "        Returns:\n",
    "            {Categorical} -- Policy: Categorical distribution\n",
    "            {torch.tensor} -- Value function: Value\n",
    "        \"\"\"\n",
    "        # Set observation as input to the model\n",
    "        h = obs\n",
    "        # Forward observation encoder\n",
    "        if len(self.observation_space_shape) > 1:\n",
    "            batch_size = h.size()[0]\n",
    "            # Propagate input through the visual encoder\n",
    "            h = F.relu(self.conv1(h))\n",
    "            h = F.relu(self.conv2(h))\n",
    "            h = F.relu(self.conv3(h))\n",
    "            # Flatten the output of the convolutional layers\n",
    "            h = h.reshape((batch_size, -1))\n",
    "\n",
    "        # Feed hidden layer\n",
    "        h = F.relu(self.lin_hidden(h))\n",
    "        \n",
    "        # Forward transformer blocks\n",
    "        h, memory = self.transformer(h, memory, memory_mask, memory_indices)\n",
    "\n",
    "        # Decouple policy from value\n",
    "        # Feed hidden layer (policy)\n",
    "        h_policy = F.relu(self.lin_policy(h))\n",
    "        # Feed hidden layer (value function)\n",
    "        h_value = F.relu(self.lin_value(h))\n",
    "        # Head: Value function\n",
    "        value = self.value(h_value).reshape(-1)\n",
    "        # Head: Policy\n",
    "        pi = [Normal(logits=branch(h_policy)) for branch in self.policy_branches]\n",
    "        \n",
    "        return pi, value, memory\n",
    "\n",
    "    def get_conv_output(self, shape:tuple) -> int:\n",
    "        \"\"\"Computes the output size of the convolutional layers by feeding a dummy tensor.\n",
    "\n",
    "        Arguments:\n",
    "            shape {tuple} -- Input shape of the data feeding the first convolutional layer\n",
    "\n",
    "        Returns:\n",
    "            {int} -- Number of output features returned by the utilized convolutional layers\n",
    "        \"\"\"\n",
    "        o = self.conv1(torch.zeros(1, *shape))\n",
    "        o = self.conv2(o)\n",
    "        o = self.conv3(o)\n",
    "        return int(np.prod(o.size()))\n",
    "    \n",
    "    def get_grad_norm(self):\n",
    "        \"\"\"Returns the norm of the gradients of the model.\n",
    "        \n",
    "        Returns:\n",
    "            {dict} -- Dictionary of gradient norms grouped by layer name\n",
    "        \"\"\"\n",
    "        grads = {}\n",
    "        if len(self.observation_space_shape) > 1:\n",
    "            grads[\"encoder\"] = self._calc_grad_norm(self.conv1, self.conv2, self.conv3)  \n",
    "            \n",
    "        grads[\"linear_layer\"] = self._calc_grad_norm(self.lin_hidden)\n",
    "        \n",
    "        transfomer_blocks = self.transformer.transformer_blocks\n",
    "        for i, block in enumerate(transfomer_blocks):\n",
    "            grads[\"transformer_block_\" + str(i)] = self._calc_grad_norm(block)\n",
    "        \n",
    "        for i, head in enumerate(self.policy_branches):\n",
    "            grads[\"policy_head_\" + str(i)] = self._calc_grad_norm(head)\n",
    "        \n",
    "        grads[\"lin_policy\"] = self._calc_grad_norm(self.lin_policy)\n",
    "        grads[\"value\"] = self._calc_grad_norm(self.lin_value, self.value)\n",
    "        grads[\"model\"] = self._calc_grad_norm(self, self.value)\n",
    "          \n",
    "        return grads\n",
    "    \n",
    "    def _calc_grad_norm(self, *modules):\n",
    "        \"\"\"Computes the norm of the gradients of the given modules.\n",
    "\n",
    "        Arguments:\n",
    "            modules {list} -- List of modules to compute the norm of the gradients of.\n",
    "\n",
    "        Returns:\n",
    "            {float} -- Norm of the gradients of the given modules. \n",
    "        \"\"\"\n",
    "        grads = []\n",
    "        for module in modules:\n",
    "            for name, parameter in module.named_parameters():\n",
    "                grads.append(parameter.grad.view(-1))\n",
    "        return torch.linalg.norm(torch.cat(grads)).item() if len(grads) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e824a520-af0e-4bc5-8482-bf34c7fac53d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\"hidden_layer_size\": 128,\n",
    "          \"transformer\": \n",
    "               {\"num_blocks\": 4,\n",
    "                \"embed_dim\": 128,\n",
    "                \"num_heads\": 1,\n",
    "                \"memory_length\": 32,\n",
    "                \"positional_encoding\": \"\", # options: \"\" \"relative\" \"learned\"\n",
    "                \"layer_norm\": \"pre\" ,# options: \"\" \"pre\" \"post\"\n",
    "                \"gtrxl\": True,\n",
    "                \"gtrxl_bias\": 0.0}}\n",
    "observation_space = torch.rand((3,70,310))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f76961-b981-4c29-aefa-c7eb9381d5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ActorCriticModel(config, observation_space, [2], 500)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115eed6-5d59-4888-8e7c-ecb981580db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vista kernel",
   "language": "python",
   "name": "vista"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
